{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1bcc69",
   "metadata": {},
   "source": [
    "# Smart Factory Energy Prediction – Final Solution\n",
    "This notebook contains the **complete code** for:\n",
    "1. Data loading & cleaning\n",
    "2. Exploratory analysis & feature selection\n",
    "3. Train/Val/Test split\n",
    "4. Model training & hyper‑parameter tuning (Ridge, Lasso, RandomForest, XGBoost, PyTorch MLP)\n",
    "5. Final evaluation & explainability\n",
    "6. Model persistence\n",
    "\n",
    "> Generated automatically on 2025‑05‑09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, warnings, os, random, math, joblib, matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 42\n",
    "np.random.seed(SEED); random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09652aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Data Load ------------\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Target to numeric\n",
    "df['equipment_energy_consumption'] = pd.to_numeric(df['equipment_energy_consumption'], errors='coerce')\n",
    "df = df.dropna(subset=['equipment_energy_consumption'])\n",
    "\n",
    "# Drop timestamp\n",
    "if 'timestamp' in df.columns:\n",
    "    df = df.drop(columns=['timestamp'])\n",
    "\n",
    "# Convert object columns\n",
    "for col in df.select_dtypes('object').columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Fill missing with median\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "print('Dataset shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Remove random variables\n",
    "for col in ['random_variable1','random_variable2']:\n",
    "    if col in df.columns: df = df.drop(columns=[col])\n",
    "\n",
    "# Drop highly correlated pairs (|ρ|>0.8)\n",
    "corr = df.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape),k=1).astype(bool))\n",
    "to_drop = [c for c in upper.columns if any(upper[c] > 0.8)]\n",
    "df = df.drop(columns=to_drop)\n",
    "print('Dropped (high corr):', to_drop)\n",
    "\n",
    "# Mutual information top‑k\n",
    "target = 'equipment_energy_consumption'\n",
    "X_all = df.drop(columns=[target]); y_all = df[target]\n",
    "mi_scores = mutual_info_regression(X_all, y_all, random_state=SEED)\n",
    "mi_series = pd.Series(mi_scores, index=X_all.columns).sort_values(ascending=False)\n",
    "top_k = 25\n",
    "selected_feats = mi_series.head(top_k).index.tolist()\n",
    "print('Selected features:', selected_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[selected_feats]\n",
    "y = df[target].values\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val       = train_test_split(X_trainval, y_trainval, test_size=0.125, random_state=SEED)\n",
    "print(f'Train {X_train.shape}, Val {X_val.shape}, Test {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def rmse(a,b): return mean_squared_error(a,b,squared=False)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ---- Ridge\n",
    "ridge_pipe = Pipeline([('scale',StandardScaler()),('ridge',Ridge())])\n",
    "ridge_grid = {'ridge__alpha':[0.01,0.1,1,10,100]}\n",
    "ridge_cv = GridSearchCV(ridge_pipe, ridge_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "results['Ridge'] = ridge_cv.best_estimator_\n",
    "\n",
    "# ---- Lasso\n",
    "lasso_pipe = Pipeline([('scale',StandardScaler()),('lasso',Lasso(max_iter=5000))])\n",
    "lasso_grid = {'lasso__alpha':[0.001,0.01,0.1,1,10]}\n",
    "lasso_cv = GridSearchCV(lasso_pipe, lasso_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "results['Lasso'] = lasso_cv.best_estimator_\n",
    "\n",
    "# ---- Random Forest\n",
    "rf_grid = {'n_estimators':[300,600], 'max_depth':[None,20,40], 'min_samples_leaf':[1,2]}\n",
    "rf_cv = RandomizedSearchCV(RandomForestRegressor(random_state=SEED,n_jobs=-1),\n",
    "                           rf_grid, n_iter=12, cv=3,\n",
    "                           scoring='neg_root_mean_squared_error', random_state=SEED, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "results['RandomForest'] = rf_cv.best_estimator_\n",
    "\n",
    "# ---- XGBoost\n",
    "xgb_grid = {'learning_rate':[0.01,0.05,0.1],\n",
    "            'max_depth':[3,5,7],\n",
    "            'subsample':[0.7,1.0],\n",
    "            'colsample_bytree':[0.7,1.0],\n",
    "            'n_estimators':[400,800]}\n",
    "xgb_cv = RandomizedSearchCV(xgb.XGBRegressor(objective='reg:squarederror', random_state=SEED, n_jobs=-1),\n",
    "                            xgb_grid, n_iter=20, cv=3,\n",
    "                            scoring='neg_root_mean_squared_error', random_state=SEED, n_jobs=-1)\n",
    "xgb_cv.fit(X_train, y_train, eval_set=[(X_val,y_val)], verbose=False)\n",
    "results['XGBoost'] = xgb_cv.best_estimator_\n",
    "\n",
    "# ---- PyTorch MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,d_in):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in,128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.25),\n",
    "            nn.Linear(128,64),  nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.25),\n",
    "            nn.Linear(64,1))\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "scaler_pt = StandardScaler().fit(X_train)\n",
    "def to_tensor(a): return torch.tensor(a, dtype=torch.float32)\n",
    "train_ds = TensorDataset(to_tensor(scaler_pt.transform(X_train)), to_tensor(y_train).view(-1,1))\n",
    "val_ds   = TensorDataset(to_tensor(scaler_pt.transform(X_val)),   to_tensor(y_val).view(-1,1))\n",
    "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mlp = MLP(X_train.shape[1]).to(device)\n",
    "opt = optim.AdamW(mlp.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "best_val = math.inf; patience=0\n",
    "for epoch in range(200):\n",
    "    mlp.train()\n",
    "    for xb,yb in train_dl:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(); loss = loss_fn(mlp(xb), yb); loss.backward(); opt.step()\n",
    "    mlp.eval()\n",
    "    with torch.no_grad():\n",
    "        vloss = loss_fn(mlp(to_tensor(scaler_pt.transform(X_val)).to(device)),\n",
    "                        to_tensor(y_val).view(-1,1).to(device)).item()\n",
    "    if vloss < best_val-1e-4:\n",
    "        best_val = vloss; patience=0; torch.save(mlp.state_dict(), 'best_mlp.pt')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if patience>=20: break\n",
    "mlp.load_state_dict(torch.load('best_mlp.pt'))\n",
    "results['MLP'] = (mlp, scaler_pt)\n",
    "\n",
    "# ---- Leaderboard on validation\n",
    "from collections import OrderedDict\n",
    "val_scores = OrderedDict()\n",
    "for name, model in results.items():\n",
    "    if name=='MLP':\n",
    "        y_pred = model[0](to_tensor(model[1].transform(X_val)).to(device)).cpu().detach().numpy().flatten()\n",
    "    else:\n",
    "        y_pred = model.predict(X_val)\n",
    "    val_scores[name] = rmse(y_val, y_pred)\n",
    "print('Validation RMSE leaderboard:', val_scores)\n",
    "best_name = min(val_scores, key=val_scores.get)\n",
    "print('Best model:', best_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "\n",
    "if best_name=='MLP':\n",
    "    mlp, scaler_best = results['MLP']\n",
    "    test_pred = mlp(to_tensor(scaler_best.transform(X_test)).to(device)).cpu().detach().numpy().flatten()\n",
    "else:\n",
    "    best_model = results[best_name]\n",
    "    best_model.fit(pd.concat([X_train, X_val]), pd.concat([pd.Series(y_train), pd.Series(y_val)]))\n",
    "    test_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse_test = rmse(y_test, test_pred)\n",
    "mae_test  = mean_absolute_error(y_test, test_pred)\n",
    "r2_test   = r2_score(y_test, test_pred)\n",
    "print(f'Test RMSE {rmse_test:.3f}  MAE {mae_test:.3f}  R² {r2_test:.4f}')\n",
    "\n",
    "# Explainability (tree -> SHAP)\n",
    "if best_name in {'RandomForest','XGBoost'}:\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test.sample(400, random_state=SEED))\n",
    "    shap.summary_plot(shap_values, X_test.sample(400, random_state=SEED), feature_names=X_test.columns)\n",
    "elif best_name in {'Ridge','Lasso'}:\n",
    "    coef = pd.Series(best_model.named_steps['lasso'].coef_ if best_name=='Lasso' else best_model.named_steps['ridge'].coef_,\n",
    "                     index=X_train.columns).sort_values(key=np.abs, ascending=False)\n",
    "    coef.head(20).plot(kind='barh'); plt.gca().invert_yaxis(); plt.title('Top coefficients')\n",
    "else:\n",
    "    perm = permutation_importance(mlp, scaler_best.transform(X_test), y_test, n_repeats=15, random_state=SEED,\n",
    "                                  scoring='neg_root_mean_squared_error')\n",
    "    imp = pd.Series(perm.importances_mean, index=X_test.columns).sort_values(ascending=False)\n",
    "    imp.head(20).plot(kind='barh'); plt.gca().invert_yaxis(); plt.title('Permutation Importance (MLP)')\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}